{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 - Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assigment you will be coding for a Linear Regression task hands-on. (10 Points)\n",
    "\n",
    "The notebook uses some popular libraries. If your environment is missing any of these libraries, you can install them using the following `pip` commands:\n",
    "\n",
    "```bash\n",
    "!pip install matplotlib seaborn scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import math\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#make sizes bigger for readability\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 17})\n",
    "plt.rcParams[\"figure.figsize\"] = (12,12)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load the California Housing dataset\n",
    "housing = fetch_california_housing()\n",
    "# Convert the dataset into a DataFrame\n",
    "df = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
    "df['MedHouseVal'] = housing.target  # Add the target (median house value)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of Instances:\n",
    "\n",
    "    20640\n",
    "Number of Attributes:\n",
    "\n",
    "    8 numeric, predictive attributes and the target\n",
    "Attribute Information:\n",
    "\n",
    "        MedInc median income in block group\n",
    "\n",
    "        HouseAge median house age in block group\n",
    "\n",
    "        AveRooms average number of rooms per household\n",
    "\n",
    "        AveBedrms average number of bedrooms per household\n",
    "\n",
    "        Population block group population\n",
    "\n",
    "        AveOccup average number of household members\n",
    "\n",
    "        Latitude block group latitude\n",
    "\n",
    "        Longitude block group longitude\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "display(df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Explore data for missingness\n",
    "print(df.info())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Check statistics of the data\n",
    "print(df.describe())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Display the first few rows\n",
    "print(df.head())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Select multiple features for the correlation check\n",
    "X_all = df[['MedInc', 'AveRooms', 'AveOccup', 'HouseAge', 'Latitude', 'Longitude']]\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = X_all.corr()\n",
    "\n",
    "# Visualize the correlation matrix\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix of Features')\n",
    "plt.show()\n",
    "\n",
    "# Note that correlation between Latitude and Longitude is coming from geographical location of California"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#display scatter_matrix also\n",
    "fig = plt.figure()\n",
    "scatter_matrix(df,figsize =(25,25),alpha=0.9,diagonal=\"kde\",marker=\"o\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Residual Sum of Squares (RSS)\n",
    "\n",
    "$$\n",
    "RSS = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$$ y_i \\text{ is the actual value} $$\n",
    "\n",
    "$$ \\hat{y}_i \\text{ is the predicted value} $$\n",
    "\n",
    "$$ n \\text{ is the number of observations} $$\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Residual Standard Error (RSE)\n",
    "\n",
    "$$\n",
    "RSE = \\sqrt{\\frac{RSS}{n - p - 1}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$$ RSS \\text{ is the Residual Sum of Squares} $$\n",
    "\n",
    "$$ n \\text{ is the number of observations} $$\n",
    "\n",
    "$$ p \\text{ is the number of predictors (excluding the intercept)} $$\n",
    "\n",
    "---\n",
    "\n",
    "### 3. t-statistic\n",
    "\n",
    "$$\n",
    "t = \\frac{\\hat{\\beta_j}}{SE(\\hat{\\beta_j})}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$$ \\hat{\\beta_j} \\text{ is the estimated coefficient for predictor } j $$\n",
    "\n",
    "$$ SE(\\hat{\\beta_j}) \\text{ is the standard error of the estimated coefficient for predictor } j $$\n",
    "\n",
    "---\n",
    "\n",
    "### 4. p-value\n",
    "\n",
    "$$\n",
    "p = 2 \\cdot (1 - T(\\lvert t \\rvert, df))\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$$ t \\text{ is the t-statistic} $$\n",
    "\n",
    "$$ df \\text{ is the degrees of freedom, calculated as } n - p - 1 $$\n",
    "\n",
    "$$ T \\text{ is the CDF of the t-distribution} $$\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Relevant Metrics"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Task 1: Fill the missing parts (#TODO) of metric computations</span> (1 Point Each, 3 Points)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def compute_rss(y, y_pred):\n",
    "    \"\"\"\n",
    "    Compute Residual Sum of Squares (RSS)\n",
    "    y: array of true target values\n",
    "    y_pred: array of predicted target values\n",
    "    \"\"\"\n",
    "    rss = 0\n",
    "    for y_elt, y_pred_elt in zip(y, y_pred):\n",
    "        rss += math.pow(y_elt - y_pred_elt, 2)\n",
    "    \n",
    "    return rss\n",
    "\n",
    "\n",
    "def compute_rse(y, y_pred, n, p):\n",
    "    \"\"\"\n",
    "    Compute Residual Standard Error (RSE)\n",
    "    y: array of true target values\n",
    "    y_pred: array of predicted target values\n",
    "    n: number of observations\n",
    "    p: number of predictors\n",
    "    \"\"\"\n",
    "    rss = compute_rss(y, y_pred)\n",
    "    \n",
    "    return math.sqrt(rss/(n-p-1))\n",
    "\n",
    "def compute_pvalue(X, y, y_pred):\n",
    "    '''\n",
    "    Compute p-values for the coefficients of a linear regression model.\n",
    "    \n",
    "    X: array of features\n",
    "    y: array of true target values\n",
    "    y_pred: array of predicted target values\n",
    "    return: p-values for each feature\n",
    "    '''\n",
    "    n, p = X.shape  # Number of observations (n) and number of predictors (p)\n",
    "    \n",
    "    # Compute RSS and RSE\n",
    "    rss = compute_rss(y, y_pred)\n",
    "    rse = compute_rse(y, y_pred, n, p)\n",
    "    \n",
    "    # # Add intercept (constant term) to the design matrix X\n",
    "    X = np.c_[np.ones(n), X]\n",
    "    \n",
    "    # Calculate (X^T X)^-1\n",
    "    XTX_inv = np.linalg.inv(np.dot(X.T, X))\n",
    "    \n",
    "    # Compute standard error (SE) for each coefficient\n",
    "    se = np.sqrt(np.diagonal(rse ** 2 * XTX_inv))\n",
    "    \n",
    "    # Fit the model to compute the coefficients (betas)\n",
    "    beta_hat = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "    \n",
    "    # Compute t-statistics for each coefficient\n",
    "    t_stats = beta_hat / se\n",
    "    \n",
    "    degrees_of_freedom = n - p - 1\n",
    "\n",
    "    # Compute p-values\n",
    "    p_values = 2 * (1 - stats.t.cdf(np.abs(t_stats), df=degrees_of_freedom))\n",
    "    \n",
    "    return p_values\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with single predictor "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Select features and target\n",
    "X = df[['AveRooms']]\n",
    "#z-normalize the data for each column\n",
    "X = (X - X.mean()) / X.std()\n",
    "y = df['MedHouseVal']\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing) with a fixing seed that ensures same split every time\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "independent_scaler = StandardScaler()\n",
    "X_train = independent_scaler.fit_transform(X_train)\n",
    "X_test = independent_scaler.transform(X_test)\n",
    "\n",
    "# Create a linear regression model\n",
    "model_1 = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "model_1.fit(X_train, y_train)\n",
    "\n",
    "# Get the coefficients\n",
    "print(f\"Intercept (β0): {model_1.intercept_}\")\n",
    "print(f\"Coefficients (β1, β2): {model_1.coef_}\")\n",
    "\n",
    "#Compute RSS for training data\n",
    "y_pred = model_1.predict(X_train)\n",
    "\n",
    "# Compute RSS\n",
    "rss = compute_rss(y_train, y_pred)\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared_all = model_1.score(X_train, y_train)\n",
    "\n",
    "# Compute the p-value\n",
    "p_value = compute_pvalue(X_train, y_train, y_pred)\n",
    "\n",
    "# Display the coefficients and p-values in a DataFrame\n",
    "coefficients = np.concatenate([[model_1.intercept_], model_1.coef_])\n",
    "p_values = np.concatenate([ p_value])\n",
    "\n",
    "display(pd.DataFrame(pd.DataFrame({'features': ['intercept'] + list(X.columns), 'coefficients': coefficients, 'p-values': p_values})))\n",
    "print(f\"RSS (test data): {rss}\")\n",
    "print(f\"R-squared (test data): {r_squared_all}\")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Task 2: Use 'MedInc', 'AveRooms', 'AveOccup', 'HouseAge', 'Latitude', 'Longitude' as predictors.</span> (2 Points)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# X_all = #TODO\n",
    "y = df['MedHouseVal']\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing) with a fixing seed that ensures same split every time\n",
    "X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(X_all, y, test_size=0.2, random_state=42)\n",
    "independent_scaler = StandardScaler()\n",
    "X_train_all = independent_scaler.fit_transform(X_train_all)\n",
    "X_test_all = independent_scaler.transform(X_test_all)\n",
    "\n",
    "# Fit the linear regression model\n",
    "model_2 = LinearRegression()\n",
    "model_2.fit(X_train_all, y_train_all)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred_all = model_2.predict(X_test_all)\n",
    "\n",
    "#Code this part\n",
    "rss = compute_rss(y_test_all, y_pred_all)\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared_all = model_2.score(X_test_all, y_test_all)\n",
    "\n",
    "# Compute the p-value\n",
    "p_value = compute_pvalue(X_test_all, y_test_all, y_pred_all)\n",
    "\n",
    "# Display the coefficients and p-values in a DataFrame\n",
    "coefficients = np.concatenate([[model_2.intercept_], model_2.coef_])\n",
    "p_values = np.concatenate([ p_value])\n",
    "\n",
    "# pd.DataFrame({'features': ['intercept'] + list(X_all.columns), 'coefficients': coefficients, 'p-values': p_values})\n",
    "display(pd.DataFrame({'features': ['intercept'] + list(X_all.columns), 'coefficients': coefficients, 'p-values': p_values}))\n",
    "print(f\"RSS (test data): {rss}\")\n",
    "print(f\"R-squared (test data): {r_squared_all}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Task 3: Try model performance on different K values by using the code below, observe the effect of very large K values which one would you pick?</span> (3 Points)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "X_all = df[['MedInc', 'AveRooms', 'AveOccup', 'HouseAge', 'Latitude', 'Longitude']]\n",
    "X_all = (X_all - X_all.mean()) / X_all.std()\n",
    "y = df['MedHouseVal']\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing) with a fixing seed that ensures same split every time\n",
    "X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(X_all, y, test_size=0.2, random_state=42)\n",
    "independent_scaler = StandardScaler()\n",
    "X_train_all = independent_scaler.fit_transform(X_train_all)\n",
    "X_test_all = independent_scaler.transform(X_test_all)\n",
    "\n",
    "#Fit the KNN model (you can tune 'n_neighbors' for optimal performance)\n",
    "knn_model = KNeighborsRegressor(n_neighbors=1)\n",
    "knn_model.fit(X_train_all, y_train_all)\n",
    "\n",
    "#Make predictions on the test set\n",
    "y_pred_knn = knn_model.predict(X_test_all)\n",
    "\n",
    "#Compute RSS and R-squared\n",
    "rss_knn = compute_rss(y_test, y_pred_knn)\n",
    "r2_knn = r2_score(y_test_all, y_pred_knn)\n",
    "print(f\"KNN Model RSS: {rss_knn}\")\n",
    "print(f\"KNN Model R-squared: {r2_knn}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Task 4: Comment on R-squared and RSS values</span> (1 Point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Make predictions on the test set for the first model (only AveRooms)\n",
    "y_pred = model_1.predict(X_test)\n",
    "\n",
    "# Make predictions on the test set for the second model (multiple features)\n",
    "y_pred_all = model_2.predict(X_test_all)\n",
    "\n",
    "# Make predictions using the KNN model\n",
    "y_pred_knn = knn_model.predict(X_test_all)  # Use scaled features for KNN\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Model 1: True vs Fitted (only AveRooms)\n",
    "sns.scatterplot(x=y_pred, y=y_test, color='blue', label='Model 1 (AveRooms)', alpha=0.1)\n",
    "\n",
    "# Model 2: True vs Fitted (multiple features)\n",
    "sns.scatterplot(x=y_pred_all, y=y_test_all, color='red', label='Model 2 (Multiple features)', alpha=0.1)\n",
    "\n",
    "# KNN Model: True vs Fitted\n",
    "sns.scatterplot(x=y_pred_knn, y=y_test_all, color='green', label='KNN Model', alpha=0.1)\n",
    "\n",
    "# Add perfect prediction line\n",
    "plt.plot([min(y_pred_all), max(y_pred_all)], [min(y_test_all), max(y_test_all)], color='black', linestyle='--', label='Perfect Prediction')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Fitted Values (Predicted)')\n",
    "plt.ylabel('True Values')\n",
    "plt.title('True vs Fitted Values for Model 1 and Model 2')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Task 5: Compute residuals</span> (1 Point)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "### 2. Residuals vs Fitted\n",
    "\n",
    "# Compute residuals #TODO\n",
    "residuals_model_1 = None #TODO\n",
    "residuals_model_2 = None #TODO \n",
    "residuals_knn = None #TODO \n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Residuals vs Fitted for Model 1 (only AveRooms)\n",
    "sns.scatterplot(x=y_pred, y=residuals_model_1, color='blue', label='Model 1 (AveRooms)', alpha=0.1)\n",
    "\n",
    "# Residuals vs Fitted for Model 2 (multiple features)\n",
    "sns.scatterplot(x=y_pred_all, y=residuals_model_2, color='red', label='Model 2 (Multiple features)', alpha=0.1)\n",
    "\n",
    "# Residuals vs Fitted for KNN Model\n",
    "sns.scatterplot(x=y_pred_knn, y=residuals_knn, color='green', label='KNN Model', alpha=0.1)\n",
    "\n",
    "# Add horizontal line at 0 (perfect prediction residual)\n",
    "plt.axhline(0, color='black', linestyle='--')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Fitted Values (Predicted)')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals vs Fitted Values for Model 1 and Model 2')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
